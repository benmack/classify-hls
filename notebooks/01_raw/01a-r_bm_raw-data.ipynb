{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this project we use the following raw data:\n",
    "\n",
    "* *Corine Land Cover* (CLC) from 2018 and information about the class nomenclature.\n",
    "\n",
    "* Sentinel-2 grid\n",
    "\n",
    "* Harmonized Landsat Sentinel-2 (HLS)\n",
    "\n",
    "This notebook describes the raw data collection and creation process. \n",
    "Thus all the data described here can be found in the *data/raw* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from shapely import wkt\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import nasa_hls\n",
    "\n",
    "from src import configs\n",
    "prjconf = configs.ProjectConfigParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prepare the data for the following tiles this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['32UNU', '32UPU', '32UQU', '33UUP']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tilenames = prjconf.get(\"Params\", \"tiles\").split(\" \")\n",
    "tilenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create raw data\n",
    "\n",
    "### CLC\n",
    "\n",
    "We downloaded *Corine Land Cover Raster - 100m* dataset manually after registration from [Copernicus Land Monitoring Service](https://land.copernicus.eu/pan-european/corine-land-cover/clc2018?tab=download) and extracted the file into *data/raw/clc/clc2018_clc2018_v2018_20b2_raster100m*.\n",
    "The most important file is *data/raw/clc/clc2018_clc2018_v2018_20b2_raster100m/clc2018_clc2018_V2018.20b2.tif*\n",
    "\n",
    "We copied the CLC legend from the *CORINE LAND COVER LEGEND* table found on the [nomenclature site of clc.gios.gov.pl](http://clc.gios.gov.pl/index.php/9-gorne-menu/clc-informacje-ogolne/58-klasyfikacja-clc-2), pasted it into LibreOffice Calc and saved it as ';'-separated csv file under *data/raw/clc/clc_legend_raw.csv*.\n",
    "\n",
    "An extended legend with the empty cells filled up and the level 2 and 3 class indices added is created here in the following cell and can be found under *data/raw/clc/clc_legend.csv* once the cell has been executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path__clc_legend_raw = prjconf.get_path(\"Raw\", \"rootdir\") / \"clc\" / \"clc_legend_raw.csv\"\n",
    "path__clc_legend = prjconf.get_path(\"Raw\", \"rootdir\") / \"clc\" / \"clc_legend.csv\"\n",
    "\n",
    "if not path__clc_legend.exists():\n",
    "    clc_legend = pd.read_csv(path__clc_legend_raw, delimiter=\";\").iloc[0:44, :]\n",
    "    clc_legend.columns = [\"l1_name\", \"l2_name\", \"l3_name\", \"grid_code\", \"rgb\"]\n",
    "    clc_legend_ids = clc_legend[\"l3_name\"].str[:5].str.split(\".\", expand=True)\n",
    "    clc_legend[\"l1_id\"] = clc_legend_ids[0].astype(\"uint8\")\n",
    "    clc_legend[\"l2_id\"] = (clc_legend_ids[0] + clc_legend_ids[1]).astype(\"uint8\")\n",
    "    clc_legend[\"l3_id\"] = (clc_legend_ids[0] + clc_legend_ids[1] + clc_legend_ids[2]).astype(\"int\")\n",
    "    clc_legend[\"l1_name\"] = clc_legend[\"l1_name\"].str[3::]\n",
    "    clc_legend[\"l2_name\"] = clc_legend[\"l2_name\"].str[4::]\n",
    "    clc_legend[\"l3_name\"] = clc_legend[\"l3_name\"].str[6::]\n",
    "    clc_legend = clc_legend.fillna(method=\"ffill\")\n",
    "    clc_legend.to_csv(path__clc_legend, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast access to important file paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ben/Devel/Projects/classify-hls/data/raw/clc/clc2018_clc2018_v2018_20b2_raster100m/clc2018_clc2018_V2018.20b2.tif\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/clc/clc_legend.csv\n"
     ]
    }
   ],
   "source": [
    "print(prjconf.get_path(\"Raw\", \"clc\"))\n",
    "print(prjconf.get_path(\"Raw\", \"clc_legend\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tile grid\n",
    "\n",
    "We download the Sentinel-2 grid in the following cell. \n",
    "The link to this nice Sentinel-2 grid file has been found on the [bencevans/sentinel-2-grid GitHub project](https://github.com/bencevans/sentinel-2-grid). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://unpkg.com/sentinel-2-grid/data/grid.json'\n",
    "path__tile_grid = prjconf.get_path(\"Raw\", \"tile_grid\")\n",
    "path__tile_grid.parent.mkdir(exist_ok=True, parents=True)\n",
    "if not path__tile_grid.exists():\n",
    "    urlretrieve(url, path__tile_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this file we create single footprint file for the tile we want to process.\n",
    "This is a good starting point for using Snakemake later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprints_exist = [prjconf.get_path(\"Raw\", \"tile_footprint\", tile).exists() for tile in tilenames]\n",
    "if not all(footprints_exist):\n",
    "    tile_grid = gpd.read_file(path__tile_grid)\n",
    "    for tile in tilenames:\n",
    "        path__tile_footprint = prjconf.get_path(\"Raw\", \"tile_footprint\", tile)\n",
    "        if not Path(path__tile_footprint).exists() or overwrite:\n",
    "            tile = tile_grid[tile_grid[\"name\"] == tile]\n",
    "            tile = tile.to_crs(epsg=tile[\"epsg\"].values[0])\n",
    "            tile[\"geometry\"] = tile[\"utmWkt\"].apply(wkt.loads)\n",
    "            Path(path__tile_footprint).parent.mkdir(parents=True, exist_ok=True)\n",
    "            tile.to_file(path__tile_footprint, driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast access to important parameters and file paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ben/Devel/Projects/classify-hls/data/raw/footprints/tiles/tiles_grid.geojson\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/footprints/tiles/footprint_32UNU.gpkg\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/footprints/tiles/footprint_32UPU.gpkg\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/footprints/tiles/footprint_32UQU.gpkg\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/footprints/tiles/footprint_33UUP.gpkg\n"
     ]
    }
   ],
   "source": [
    "print(prjconf.get_path(\"Raw\", \"tile_grid\"))\n",
    "\n",
    "for tile in tilenames:\n",
    "    print(prjconf.get_path(\"Raw\", \"tile_footprint\", tile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HLS\n",
    "\n",
    "We download data from the [Harmonized Landsat Sentinel-2 (HLS) Product](https://hls.gsfc.nasa.gov/) with the [nasa_hls Python package](https://benmack.github.io/nasa_hls/build/html/index.html) in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "100%|██████████| 67/67 [00:00<00:00, 2801.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scenes queried for tile 32UNU: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "100%|██████████| 67/67 [00:00<00:00, 2839.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scenes queried for tile 32UPU: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 2901.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scenes queried for tile 32UQU: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "  0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scenes queried for tile 33UUP: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [04:00<00:00,  3.59s/it] \n"
     ]
    }
   ],
   "source": [
    "for tile in tilenames:\n",
    "    df_datasets = nasa_hls.get_available_datasets(products=[\"L30\"],\n",
    "                                                  years=[2018],\n",
    "                                                  tiles=[tile],\n",
    "                                                  return_list=False)\n",
    "    print(f\"Number of scenes queried for tile {tile}: {df_datasets.shape[0]}\")\n",
    "    dir__hls_tile = prjconf.get_path(\"Raw\", \"hls_tile\", tile=tile)\n",
    "    nasa_hls.download_batch(dir__hls_tile, df_datasets)\n",
    "    \n",
    "    path__hls_tile_lut = prjconf.get_path(\"Raw\", \"hls_tile_lut\", tile=tile)\n",
    "    if not path__hls_tile_lut.exists():\n",
    "        hdf_files = list(dir__hls_tile.rglob(\"*.hdf\"))\n",
    "        df = nasa_hls.dataframe_from_hdf_paths(hdf_files)\n",
    "        df[\"tile\"] = tile\n",
    "        df.to_csv(path__hls_tile_lut, index=False)\n",
    "    else:\n",
    "        pass \n",
    "        # TODO: it would be good to check if there are new files and rewrite the csv ONLY if this is the case "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast access to important directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ben/Devel/Projects/classify-hls/data/raw/hls/32UNU\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/hls/hls_32UNU_lut.csv\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/hls/32UPU\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/hls/hls_32UPU_lut.csv\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/hls/32UQU\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/hls/hls_32UQU_lut.csv\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/hls/33UUP\n",
      "/home/ben/Devel/Projects/classify-hls/data/raw/hls/hls_33UUP_lut.csv\n"
     ]
    }
   ],
   "source": [
    "for tile in tilenames:\n",
    "    print(prjconf.get_path(\"Raw\", \"hls_tile\", tile))\n",
    "    print(prjconf.get_path(\"Raw\", \"hls_tile_lut\", tile=tile))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
